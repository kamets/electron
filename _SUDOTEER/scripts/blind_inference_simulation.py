"""
üï∂Ô∏è OPERATION BLIND INFERENCE: SENSORLESS STABILIZATION üï∂Ô∏è
Crisis: pH/EC sensors have FAILED. Water flow is STUCK ON (cannot stop).
Agent: HydrationAgent
Objective: Use historical inference to dose based on flow time and pulse counts.
"""
import asyncio
import sys
import os
import json
import dspy
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

os.environ["DSPy_DISABLE_STRUCTURED_OUTPUTS"] = "true"
os.environ["LITELLM_DROP_PARAMS"] = "true"

TELEMETRY_PATH = "telemetry/blind_inference.jsonl"
os.makedirs("telemetry", exist_ok=True)

def log_telemetry(data):
	with open(TELEMETRY_PATH, "a") as f:
		f.write(json.dumps({"timestamp": datetime.now().isoformat(), **data}) + "\n")

class BlindInference(dspy.Signature):
	"""Emergency protocol for dosing when sensors are dead and flow is continuous."""
	historical_log: str = dspy.InputField(desc="Past successful dosing patterns (pulses per Liter, time vs. pH change)")
	current_flow_rate: float = dspy.InputField(desc="Flow rate in Liters per Minute (L/min)")
	elapsed_time: int = dspy.InputField(desc="How long the water has been flowing (minutes)")
	failed_sensors: list = dspy.InputField(desc="List of offline sensors")

	inference_logic: str = dspy.OutputField(desc="Deep reasoning: Calculating dosage via historical inference (Dead Reckoning)")
	emergency_code: str = dspy.OutputField(desc="Python code for open-loop timed pulse dosing")
	uncertainty_buffer: str = dspy.OutputField(desc="Risk assessment: How much we should under-dose to prevent lethal overshoot")

async def run_blind_simulation():
	print("=" * 80)
	print("   üï∂Ô∏è  OPERATION BLIND INFERENCE: THE GHOST IN THE PIPES üï∂Ô∏è")
	print("   HydrationAgent | Flying Blind on Pure Inference")
	print("=" * 80)

	# Setup Kimi K2 (The Oracle/Teacher)
	teacher = dspy.LM(
		model="ollama_chat/kimi-k2-thinking:cloud",
		api_base="http://localhost:11434",
		cache=False
	)
	dspy.configure(lm=teacher)

	# The "Institutional Memory" Kimi must use
	history = """
	HISTORICAL DATA (Last 30 Days):
	- Average successful dose: 1.2ml pH-Up per 100L of raw source water.
	- Peristaltic Pump 'Pump-7' pulse rate: 1 pulse = 0.5ml.
	- Target: Lift pH from 4.5 (raw) to 6.2 (optimal).
	- Successful stability achieved at 2.4 pulses per 100L.
	"""

	flow_rate = 12.5 # L/min
	time_passed = 45 # minutes (Water is flowing!)
	failed = ["PH_PROBE_01", "EC_PROBE_01"]

	print(f"\n   Flow: {flow_rate}L/min | Time: {time_passed}min | STATUS: SENSORS DARK")
	print("   Kimi is performing 'Dead Reckoning' on historical traces...")

	try:
		engine = dspy.ChainOfThought(BlindInference)
		result = await asyncio.wait_for(
			asyncio.to_thread(engine, historical_log=history, current_flow_rate=flow_rate, elapsed_time=time_passed, failed_sensors=failed),
			timeout=400.0
		)

		print("\n" + "=" * 80)
		print("   üìú BLIND INFERENCE PROTOCOL üìú")
		print("=" * 80)
		print(f"\n   INFERENCE REASONING:\n{result.inference_logic[:800]}...")
		print(f"\n   EMERGENCY CODE:\n{result.emergency_code[:600]}...")
		print(f"\n   UNCERTAINTY BUFFER: {result.uncertainty_buffer}")

		# Log Telemetry
		log_telemetry({
			"scenario": "Blind Inference",
			"reasoning": result.inference_logic,
			"code": result.emergency_code,
			"buffer": result.uncertainty_buffer
		})

		# Ingest into Institutional Memory
		from backend.core.memory.vector_db import vector_db
		knowledge_item = f"""
[ADVANCED PROTOCOL: BLIND INFERENCE / DEAD RECKONING]
CRISIS: Sensor Death + Continuous Flow.
METHOD: Open-Loop Historical Inference.
CORE LOGIC: {result.inference_logic}
RATIO: Based on history of 2.4 pulses per 100L.
SAFETY: Under-dose by amount specified in uncertainty buffer.
CODE:
{result.emergency_code}
"""
		await vector_db.add_to_knowledge(
			[knowledge_item],
			[{"type": "legendary_inference", "agent": "HydrationAgent"}]
		)
		print(f"\n   [MEMORY] Operation Blind Inference archived. The Agent now knows how to 'see' without sensors.")

	except Exception as e:
		print(f"   [ERROR] Simulation failed: {e}")

if __name__ == "__main__":
	asyncio.run(run_blind_simulation())
